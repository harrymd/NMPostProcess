'''
NMPostProcess/process.py
Functions for processing NormalModes output with vector spherical harmonics (VSHs).
For usage information, see README.md.

Definitions of variables:

# File paths relating to NormalModes.
dir_NM
    NM standard for NormalModes. The path of the directory containing the NormalModes input and output files.
file_std_out
    The standard output file generated by NormalModes. It contains the mode frequencies amongst other information.
path_eigvec_base

# File paths relating to NMPostProcess.
dir_processed
    The directory (within dir_NM) which processed output is written to.
file_eigval_list
    A text file (eigenvalue_list.txt) listing the mode number and frequency.
path_discon_info

# File paths relating to PlanetaryModels.
dir_PM
    PM stands for PlanetaryModels. The path of the directory containing the model input files.

# Variables relating to the mesh used by NormalModes.
n_nodes
    The number of nodes in the mesh.
n_samples
    The number of points at which the eigenvector is specified. 
    Note: The eigenfunction is a vector displacement. It has three components which are specified at each node. At the fluid-solid boundary nodes, the displacement is specified on both the fluid side and the solid side of the boundary. Therefore if there are n_s solid nodes, n_f fluid nodes and n_sf solid-fluid boundary nodes, then the number of samples of the eigenvector will be
        n_samples = n_s + n_f + 2*n_sf
    which is greater (by n_sf) than the number of nodes,
        n_nodes = n_s + n_f + n_sf
node_idxs
    (n_samples) A list of indices which map the samples of the displacement to the node at which the sample is taken. The indices of the fluid-solid boundary nodes occur twice, because the displacement is specified on both sides of the boundary. For example, to find the coordinates at which the j_th sample of the eigenvector applies, node = nodes[node_idxs[j]] (where nodes is the list of nodes, with shape n_nodes, as output by the function process.read_mesh().)
nodes
    (3, n_nodes) The coordinates of the computational nodes.
node_attbs
    (n_samples) A list of integer attributes for each sample of the displacement:
        0   Displacement in solid (interior or free surface).
        1   Displacement in fluid (interior).
        2   Displacement in solid (at solid-fluid interface).
        6   Displacement in fluid (at solid-fluid interface).
    For second-order elements, the corresponding integers are 3, 4, 5, and 7, but these are not used.
r_discons
    A list of the radii of the solid-fluid discontinuities, starting with the outer surface. For example, Earth's list is [6371.0, 3480.0, 1221.50].
r_discon_midpoints
    A list of radial coordinates half-way between each internal discontinuity. If there are 0 or 1 internal discontinuities, this is None. The list is bracketed by the free-surface radius and 0.0. So for example, on Earth the list is [6371.0, 2350.75, 0.0], where 2350.75 is half-way between the core-mantle boundary and the inner-core boundary.
r_surface
    The outer radius of the planet.
n_shells
    The number of 'shells' (region between discontinuities, not including solid-solid discontinuities). For example, Earth has three 'shells' (mantle, outer core, inner core), ignoring the crust. 
n_discons
    The number of discontinuities, including the free surface and solid-fluid discontinuities, but not solid-solid discontinuities.
n_interior_discons
    Equal to n_discons - 1.

state_outer
    The state of the outermost shell. For example, Earth's outermost shell (ignoring the crust) is the mantle, which is solid, so this would be 'solid'.
state_list
    The state of each shell, starting with the outermost shell. For Earth (ignoring the crust), this is [solid, liquid, solid] for mantle, outer core, inner core.
n_regions
    The planet is divided into regions, where the first region is the outer surface, the second region is the interior of the first shell, the third region is the inner surface of the first shell, and so on. For example, Earth has eight regions: outer surface of mantle, interior of mantle, inner surface of mantle, outer surface of outer core, interior of outer core, inner surface of outer core, outer surface of inner core, and interior of inner core. The number of regions is 3*n_interior_discons + 2.
index_lists
    For the i_th region, index_lists[i] lists the indices of the eigenvector samples coming from that region.
boundary_tol
    A tolerance for floating point checks to determine if a point is on a boundary. This is only used for points at the free surface, which are not assigned a different node attribute by the NormalModes code (unlike fluid-solid boundary nodes).

# Variables relating to the NormalModes output.
n_modes
    The number of modes in the frequency range calculated by NM.
freq
    The frequency of a given mode (mHz).
eigvec
    (3, n_samples) The displacement of the eigenfunction, listed at each sample point.

# Variables relating to interpolation between NM and NMPostProcess.
lon_grid
    (n_lat_grid, n_lon_grid) A regular grid of longitude points.
lat_grid
    (n_lat_grid, n_lon_grid) A regular grid of latitude points.
n_lat_grid
    Number of latitude grid points. Must be an even number for SHTns. Set to 6*l_max, which should guarantee no aliasing.
n_lon_grid
    Number of longitude grid points, equal to 2*(n_lat_grid - 1).
n_radii
    Number of different radial coordinates at which sampling is performed.

# Variables relating to a specific sample point or region.
i_mode
    The mode number (for a given NormalModes run, the mode number ranges from 1 to n_modes).
i_shell
    The shell number (see n_shell for definition of 'shell'), starting at 0 for the outer shell.
is_outer
    For a given interface, is_outer == True if the interface is the outer interface, and False if it is the inner interface.
boundary_tol
r_q, r_max
    r_* is a radial coordinate in km. r_q is some query radius. r_max is the radius at which the maximum displacement occurs.
i_region_q, i_region_max, i_region_discon, i_region_interior
    i_region_* is a region index (see n_region for a definition of region). i_region_q is some query region. i_region_max is the region within which the maximum displacement occurs. i_region_discon is a list of regions which are discontinuity surfaces. i_region_interior is a list of regions which are interiors.

# Variables relating to VSH projection.
l_max
    The maximum value of angular order (l) used in the VSH expansion.
r_hat_grid, e_hat_grid, n_hat_grid
    (n_lat_grid, n_lon_grid, 3) The 'hat' vectors are Cartesian unit vectors in the spherical polar coordinate directions (radial, east, north) at each point in the grid.
eigvec_r_grid, eigvec_e_grid, eigvec_n_grid
    (n_lat_grid, n_lon_grid) The components of the eigenvector in the radial, east and north directions at each point in the grid.

# Variables relating to the NMPostProcess output.
save_spatial
    If true, the field is re-projected into spatial representation and saved.
sh_calculator
    An object created by SHTns for performing VSH calculations.
Ulm, Vlm, Wlm
    (n_coeffs) Complex vector spherical harmonic coefficients (radial, consoidal and spheroidal components) output by SHTns.
scale
    The coefficients for a given mode are divided by the absolute maximum displacement of that mode for better numerical accuracy. This absolute maximum displacement is the variable 'scale'.
l_list
    (n_coeffs) The l-value of each coefficient.
m_list
    (n_coeffs) The m-value of each coefficient.
n_coeffs
    The number of complex VSH coefficients in the expansion up to and including l_max. This is (l_max + 1)(l_max + 2)/2.
Ur, Ve, Vn, We, Wn
    (n_lat_grid, n_lon_grid) The spatial representation of the different parts of the displacement field:
        Ur  The radial part of the field.
        Ve  The eastward component of the consoidal part of the field.
        Vn  The northward component of the consoidal part of the field.
        We  The eastward component of the toroidal part of the field.
        Wn  The northward component of the toroidal part of the field.
EU, EV, EW
    The fraction of 'power' in the radial, consoidal and toroidal components, found by summing the square of the coefficients. These are normalised so that E (see below) is 1.0.
E
    The total 'power', EU + EV + EW.
E_of_l  A list of the 'energy' contained in each value of angular order. Note that the sum of E_of_l is E.

# Variables related to plotting.
fmt
    The file format ('pdf' or 'png').
show
    If True, the plot is shown.
title
    A title string. If None, no title is added.
'''

# Import modules --------------------------------------------------------------
# Import core modules.
from functools import partial
from glob import glob
import multiprocessing
import os
import pickle

# Import third-party modules
import numpy as np
from scipy.interpolate import LinearNDInterpolator 
from scipy.spatial import ConvexHull
import shtns
import ssrfpy

# Import local modules.
from common import get_list_of_modes_from_output_files, mkdir_if_not_exist, read_discon_file, read_eigenvalues, read_input_NMPostProcess

# Pre-processing steps (only performed once for a given run). -----------------
def write_eigenvalues_from_std_out_file(path_std_out, path_eigval_list = None): 
    '''
    Reads the eigenvalues (frequencies) from standard output file from the NormalModes code and (optionally) saves them in a separate file. 

    Input

    path_std_out, path_eigval_list (optional)
        See 'Definitions of variables'.

    Returns

    None
    '''

    # Skip lines until the relevant section is reached. 
    target_line = 'Transform to frequencies (mHz), and periods (s)' 
    with open(path_std_out, 'r') as in_id: 
         
        for line in in_id:
            
            line = line.strip()

            if line == target_line:

                break
        
        if not (line == target_line):
            raise ValueError('Reached end of file without finding target line')
        
        line = in_id.readline().split()
        # Create output arrays for mode number and frequency.
        i_mode     = []
        freq    = []
        while len(line) == 4:
            
            i_mode.append(int(line[1]))
            freq.append(float(line[2]))
            
            line = in_id.readline().split()
            
    # Write to eigenvalue file (if requested).
    if path_eigval_list is not None:
        
        print('Writing eigenvalue list file {:}'.format(path_eigval_list))
        with open(path_eigval_list, 'w') as out_id:
            
            for n, f in zip(i_mode, freq):
                
                out_id.write('{:10d} {:16.9f}\n'.format(n, f))
                
    return i_mode, freq

def write_eigenvalues_from_eigs_txt_file(path_eigs_txt, path_eigval_list):

    omega_squared = np.loadtxt(path_eigs_txt)
    f = np.sqrt(omega_squared)/(2.0*np.pi)
    f_mHz = f*1.0E3

    n_modes = len(f_mHz)

    print('Writing eigenvalue list file {:}'.format(path_eigval_list))
    with open(path_eigval_list, 'w') as out_id:
    
        for i in range(n_modes):
            
            out_id.write('{:10d} {:16.9f}\n'.format(i + 1, f_mHz[i]))

    return

def get_indices_of_regions(nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default'):
    '''
    For each region (outer surface, interior, and inner surface of each shell), find the indices of the samples belonging to that region.

    Input:

    See 'Definitions of variables.'

    Output:

    See 'Definitions of variables.'
    '''
    
    # Get the radius of the surface and the number of discontinuities.
    r_surface = r_discons[0]
    n_discons = len(r_discons)

    # Get the radial coordinates of the samples.
    r_nodes = np.linalg.norm(nodes, axis = 1)
    r_samples = r_nodes[node_idxs]

    # Find nodes on the free surface.
    i_shell = 0
    is_outer = True
    surface_condition, j_surface = get_samples_on_boundary(i_shell, is_outer, nodes, node_attbs, node_idxs, r_discons, state_outer)

    # Find all interior nodes (must remove the surface nodes).
    interior_condition = (((node_attbs == 0) | (node_attbs == 1)) & ~surface_condition)
    j_interior_sample = np.where(interior_condition)[0]

    # Case 1: There are no interior discontinuities.
    if n_discons == 1:
        
        # Find samples inside the object.
        index_lists_interior = [j_interior_sample]
        
        # Find samples on the surface of the object.
        index_lists_boundaries = [j_surface]

    # Case 2: There are some interior discontinuities.
    else:

        # Initialise lists.
        index_lists_interior = []
        index_lists_boundaries = [j_surface]

        # Make a list of boundaries of shells (r_surface, r1, r2, ..., 0.0).
        r_discons_bounded = np.concatenate([r_discons, [0.0]])

        # Find the indices of interior samples in each shell.
        for i_shell in range(n_discons):
            
            # Find samples at the appropriate radial distance.
            radius_condition = ((r_samples < r_discons_bounded[i_shell]) & (r_samples > r_discons_bounded[i_shell + 1]))

            # Apply the radial condition and the interior node attribute condition.
            shell_condition = (radius_condition & interior_condition)
            j_shell = np.where(shell_condition)[0]
            
            # Store.
            index_lists_interior.append(j_shell)

        # Find the indices of boundary samples in each shell.
        for i_shell in range(n_discons):

            # Loop over the outer and inner sides of each shell.
            # The outer surface of the outer shell has already been found.
            if i_shell == 0:

                is_outer_list = [False]

            elif (i_shell < (n_discons - 1)):

                is_outer_list = [True, False]

            # The innermost shell does not have an inner side.
            else:

                is_outer_list = [True]

            for is_outer in is_outer_list:
                
                # Search for the boundary samples.
                _, j_discon = get_samples_on_boundary(i_shell, is_outer, nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default')

                index_lists_boundaries.append(j_discon)

    # Merge the lists into a single list.
    # The list starts with the free surface and then the first interior region.
    index_lists = [index_lists_boundaries[0], index_lists_interior[0]]
    if len(index_lists_interior) > 1:

        for i in range(1, len(index_lists_interior)):

            # Between every interior region, there are two boundaries.
            index_lists.append(index_lists_boundaries[2*i - 1])
            index_lists.append(index_lists_boundaries[2*i])

            # The next interior region.
            index_lists.append(index_lists_interior[i])

    return index_lists_interior, index_lists_boundaries, index_lists

def get_indices_of_regions_old(nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default'):
    '''
    For each region (outer surface, interior, and inner surface of each shell), find the indices of the samples belonging to that region.

    Input:

    See 'Definitions of variables.'

    Output:

    See 'Definitions of variables.'
    '''
    
    # Get the radius of the surface and the number of discontinuities.
    r_surface = r_discons[0]
    n_discons = len(r_discons)

    # Get the radial coordinates of the samples.
    r_nodes = np.linalg.norm(nodes, axis = 1)
    r_samples = r_nodes[node_idxs]

    # Find nodes on the free surface.
    i_shell = 0
    is_outer = True
    surface_condition, j_surface = get_samples_on_boundary(i_shell, is_outer, nodes, node_attbs, node_idxs, r_discons, state_outer)

    # Find all interior nodes (must remove the surface nodes).
    interior_condition = (((node_attbs == 0) | (node_attbs == 1)) & ~surface_condition)
    j_interior_sample = np.where(interior_condition)[0]

    # Case 1: There are no interior discontinuities.
    if n_discons == 1:
        
        # Find samples inside the object.
        index_lists_interior = [j_interior_sample]
        
        # Find samples on the surface of the object.
        index_lists_boundaries = [j_surface]

    # Case 2: There are some interior discontinuities.
    else:

        # Initialise lists.
        index_lists_interior = []
        index_lists_boundaries = [j_surface]

        # Make a list of boundaries of shells (r_surface, r1, r2, ..., 0.0).
        r_discons_bounded = np.concatenate([r_discons, [0.0]])

        # Find the indices of interior samples in each shell.
        for i_shell in range(n_discons):
            
            # Find samples at the appropriate radial distance.
            radius_condition = ((r_samples < r_discons_bounded[i_shell]) & (r_samples > r_discons_bounded[i_shell + 1]))

            # Apply the radial condition and the interior node attribute condition.
            shell_condition = (radius_condition & interior_condition)
            j_shell = np.where(shell_condition)[0]
            
            # Store.
            index_lists_interior.append(j_shell)

        # Find the indices of boundary samples in each shell.
        for i_shell in range(n_discons):

            # Loop over the outer and inner sides of each shell.
            # The outer surface of the outer shell has already been found.
            if i_shell == 0:

                is_outer_list = [False]

            elif (i_shell < (n_discons - 1)):

                is_outer_list = [True, False]

            # The innermost shell does not have an inner side.
            else:

                is_outer_list = [True]

            for is_outer in is_outer_list:
                
                # Search for the boundary samples.
                _, j_discon = get_samples_on_boundary(i_shell, is_outer, nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default')

                index_lists_boundaries.append(j_discon)

    # Merge the lists into a single list.
    # The list starts with the free surface and then the first interior region.
    index_lists = [index_lists_boundaries[0], index_lists_interior[0]]
    if len(index_lists_interior) > 1:

        for i in range(1, len(index_lists_interior)):

            # Between every interior region, there are two boundaries.
            index_lists.append(index_lists_boundaries[2*i - 1])
            index_lists.append(index_lists_boundaries[2*i])

            # The next interior region.
            index_lists.append(index_lists_interior[i])

    return index_lists_interior, index_lists_boundaries, index_lists

def get_samples_on_boundary(i_shell, is_outer, nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default', surface_method = 'convhull'):
    '''
    Finds the samples of the eigvector which belong to a specified boundary.
    
    Input:

    See 'Definitions of variables.'

    surface_method
        A string specifying the method used to identify the samples on the outer surface. Currently, the supported options are
            'convhull'  (Default.) Finds the nodes belonging to the convex hull of the mesh. This only yields all of the surface nodes if the surface mesh is convex.
            'radius'    Uses the outer surface radius to find the samples on the surface. This only works if the surface is spherical.

    Output:

    condition
        (n_samples) True for the samples on the boundary, False otherwise. Therefore j_boundary = np.where(condition)[0].
    j_boundary
        The indices of the samples which belong to the boundary.
    '''

    # Case 1: The interface is the outer surface.
    if (i_shell == 0) and is_outer:

        # Find the points on the surface using the convex hull.
        # This method only works if the surface is convex.
        if surface_method == 'convhull':
        
            # Build complex hull.
            hull = ConvexHull(nodes)
            hull_indices = hull.simplices

            hull_indices = np.unique(hull_indices.flatten())

            condition = np.array([i in hull_indices for i in node_idxs], dtype = np.int)

        # Find the points on the surface based on their radial coordinate.
        # This method only works if the surface is a sphere.
        elif surface_method == 'radius':

            # Find radius of outer surface.
            r_surface = r_discons[0]

            # Set default value of comparison tolerance for boundaries.
            if boundary_tol == 'default':

                boundary_tol = r_surface*1.0E-7

            # Find indices of allowed nodes, and discard other nodes
            r_samples = np.linalg.norm(nodes[node_idxs], axis = 1)
            r_min = r_surface - boundary_tol
            condition = (r_samples > r_min)

        else:

            raise ValueError('Method for detecting surface nodes ({:}) was not recognised. Options are \'convhull\' and \'radius\'')

    # Case 2: The interface is an internal fluid-solid boundary.
    else:
        
        # Find the index of the region the sample belongs to.
        if is_outer:
            
            i_region_discon = i_shell

        else:

            i_region_discon = i_shell + 1

        # Get discon lists.
        r_discon_midpoints, state_list, n_interior_discons = get_discon_info(r_discons, state_outer)
        
        if n_interior_discons > 1:

            # Find which nodes are close to the specified discontinuity. 
            r_nodes = np.linalg.norm(nodes, axis = 1)
            r_samples = r_nodes[node_idxs]
            radius_condition = ((r_samples < r_discon_midpoints[i_region_discon - 1]) & (r_samples > r_discon_midpoints[i_region_discon]))

        else:
            
            # If there is only one internal discontinuity, we do not have to specify a radius condition to identify it.
            radius_condition = True

        # Case 2a. The query point is in a solid shell.
        if state_list[i_shell] == 'solid':

            attb_condition = (node_attbs == 2)

        # Case 2b. The query point is in a liquid shell.
        else:

            attb_condition = (node_attbs == 6)

        # Apply the attribute and radius conditions simultaneously.
        condition = (attb_condition & radius_condition)
        
    j_boundary = np.where(condition)[0]

    return condition, j_boundary

def pre_process(dir_PM, dir_NM):
    '''
    Perform some processing steps which only need to be done once for a given NormalModes run.
    See README.md for more information.
    '''

    # Create the output directories if they do not exist.
    dir_processed = os.path.join(dir_NM, 'processed')
    dir_spectral = os.path.join(dir_processed, 'spectral')
    for dir_ in [dir_processed, dir_spectral]:
        mkdir_if_not_exist(dir_)

    # Write the eigenvalue file if it doesn't already exist.
    path_eigval_list    = os.path.join(dir_processed, 'eigenvalue_list.txt')
    if not os.path.exists(path_eigval_list):
        
        # Search for the standard output file, which contains the eigenvalue information.
        #file_std_out_wc = os.path.join(dir_NM, '{:}*.txt'.format(std_out_prefix))
        path_eigs_wc = os.path.join(dir_NM, '*.txt')
        path_eigs_glob = glob(path_eigs_wc)
        n_glob = len(path_eigs_glob)
        if n_glob == 0:

            raise FileNotFoundError('Could not find any paths matching {} for eigenvalue information.'.format(path_eigs_wc))

        elif n_glob > 1:
            
            raise RuntimeError('Found more than one path matching {}, not clear which contains eigenvalue information.'.format(path_eigs_wc))

        path_eigs = path_eigs_glob[0]
    
        # Case 1: The eigenvalue log ends in eigs.txt.
        if path_eigs[-8:-4] == 'eigs':

            path_eig_txt = path_eigs
            write_eigenvalues_from_eigs_txt_file(path_eig_txt, path_eigval_list)

        # Case 2: The eigenvalue log ends in seven integers then .txt (the format of a standard output file). 
        elif all([character in list('0123456789') for character in list(path_eigs[-11:-4])]):

            path_std_out = path_eigs
            write_eigenvalues_from_std_out_file(path_std_out, path_eigval_list = path_eigval_list)
        
        else:

            raise RunTimeError('The name of the raw eigenvalue log file ({:}) does not match any known formats.'.format(path_eigs))

    else:

        print('Eigenvalue list file {:} already exists. Skipping creation.'.format(path_eigval_list))

    # Write the nodes file if it doesn't already exist.
    # This file is simply a re-written version of some of the TetGen output, for convenience.
    path_nodes = os.path.join(dir_processed, 'nodes.txt')
    if not os.path.exists(path_nodes):
        
        #nodes, tets, tet_means, tet_attrib, neighs = read_mesh(file_base)
        nodes, _, _, _, _ = read_mesh(dir_PM)
        print('Saving node file {:}'.format(path_nodes))
        np.savetxt(path_nodes, nodes)

    else:
        
        print('Node file already exists: {:}. Skipping creation.'.format(path_nodes))
        nodes = np.loadtxt(path_nodes)

    # Write the region index files if they don't already exist.
    path_index_lists = os.path.join(dir_processed, 'index_lists.txt')
    if not os.path.exists(path_index_lists):

        # Read the discontinuity radius information.
        path_discon_info = os.path.join(dir_PM, 'radii.txt')
        r_discons, state_outer = read_discon_file(path_discon_info)

        # Load sample index and attribute information.
        node_idxs, node_attbs = load_sample_indices_and_attribs(dir_NM)
            
        # Get list of indices of samples in regions (interiors and boundaries).
        _, _, index_lists = get_indices_of_regions(nodes, node_attbs, node_idxs, r_discons, state_outer, boundary_tol = 'default')

        # Save the index list.
        print('Saving index lists file: {:}'.format(path_index_lists))
        index_list_lengths = [len(x) for x in index_lists]
        n_regions = len(index_list_lengths)
        index_list_header_fmt = '{:>12d}'*n_regions + '\n'
        index_list_header = index_list_header_fmt.format(*index_list_lengths)

        with open(path_index_lists, 'w') as out_id:

            out_id.write(index_list_header)

            for index_list in index_lists:
                
                out_id.write('#\n')
                np.savetxt(out_id, index_list, fmt = '%i')

    else:

        print('Detected index list file {:}. Skipping calculation.'.format(path_index_lists))

    return

# Reading NormalModes files. --------------------------------------------------
def read_mesh(dir_PM):
    '''
    Reads the various TetGen files related to the mesh.
    
    Input

    path_base The path to the TetGen files, including the model prefix, e.g. '/path/to/mod.1'.

    Output

    nodes       See 'Definitions of variables'.
    tets        See TetGen manual.
    tet_means   Centroids of tetrahedra.
    tet_attrib  See TetGen manual.
    neighs      See TetGen manual.
    '''

    # Read the .ele file, which contains a list of tetrahedra. 
    # (See section 5.2.4 of the TetGen manual.)
    # [n_tet]   The number of tetrahedra. 
    # tets      (n_tet, 4) Each row gives the indices of the four vertices of
    #           one of the tetrahedra.
    # tet_attrib(n_tet) A tetrahedron has an 'attribute' (integer code) which
    #           can be used to identify different regions of the model.
    path_ele_regex = os.path.join(dir_PM, '*.ele')
    path_ele = glob(path_ele_regex)[0]
    mesh_info = np.loadtxt(
                    path_ele,
                    comments    = '#',
                    skiprows    = 1,
                    usecols     = (1, 2, 3, 4, 5),
                    dtype       = np.int,)
    
    # Note: Here switch to 0-based indexing.
    tets        = mesh_info[:, 0:4] - 1
    tet_attrib  = mesh_info[:, 4]

    # Read the .node file, which contains a list of nodes.
    # (See section 5.2.1 of the TetGen manual.)
    # [n_node]  The number of nodes.
    # nodes     (n_nodes, 3) The coordinates of each node.
    path_node_regex = os.path.join(dir_PM, '*.node')
    path_node = glob(path_node_regex)[0]
    nodes       = np.loadtxt(
                    path_node,
                    comments    = '#',
                    skiprows    = 1,
                    usecols     = (1, 2, 3),
                    dtype       = np.float)
                    
    # Find the mean of the corners of each tetrahedron.
    tet_means =     (   nodes[tets[:, 0]]
                    +   nodes[tets[:, 1]]
                    +   nodes[tets[:, 2]]
                    +   nodes[tets[:, 3]])/4.0
                    
    # Read the .neigh file, which lists the four neighbours (which share faces) of each tetrahedron. (Boundary faces have an index of -1.)
    # (See section 5.2.10 of the TetGen manual.)
    # [n_tet]   The number of tetrahedra.
    # neighs    (n_tet, 4) The indices of the neighbours of each tetrahedron.
    path_neigh_regex = os.path.join(dir_PM, '*.neigh')
    path_neigh = glob(path_neigh_regex)[0]
    neighs      = np.loadtxt(
                    path_neigh,
                    comments    = '#',
                    skiprows    = 1,
                    usecols     = (1, 2, 3, 4),
                    dtype       = np.int)
    # Note: Here switch to 0-based indexing.
    neighs = neighs - 1

    return nodes, tets, tet_means, tet_attrib, neighs

def load_sample_indices_and_attribs(dir_NM):
    '''
    Read the *_vlist.dat and *_vstat.dat files, and slightly reformat them to help to distinguish between samples on the inner and outer surfaces of discontinuities.

    Input:

    dir_NM
        See 'Definitions of variables'.

    Output:

    node_idxs, node_attbs
        See 'Definitions of variables'.
    '''
    
    # Read the vlist file (a list of vertex indices).
    path_vlist_regex = os.path.join(dir_NM, '*_vlist.dat')
    path_vlist = glob(path_vlist_regex)[0]
    node_idxs   = np.fromfile(path_vlist, dtype = '<i')
    # Convert to 0-based indexing.
    node_idxs   = node_idxs - 1
    
    # Read the vstat file (a list of vertex attributes).
    path_vstat_regex = os.path.join(dir_NM, '*_vstat.dat')
    path_vstat = glob(path_vstat_regex)[0]
    node_attbs  = np.fromfile(path_vstat, dtype = '<i')
    
    # Print a vertex attribute summary.
    unique_node_attbs = np.unique(node_attbs)
    n_nodes_by_attb = [np.sum(node_attbs == i) for i in unique_node_attbs]
    print('Vertex attribute summary:')
    for i in unique_node_attbs: 

        print('{:2d} {:6d}'.format(i, n_nodes_by_attb[i]))
    
    # Calculate the number of nodes and the number of samples.
    # (See 'Definitions of variables' for an explanation.)
    n_nodes = node_idxs.shape[0]
    n_samples = n_nodes_by_attb[0] + n_nodes_by_attb[1] + 2*n_nodes_by_attb[2]

    # Insert a new vertex attribute for the each of the fluid-solid boundary
    # nodes, so we can distinguish between the eigenvector on the fluid side
    # and the solid side.
    node_attbs_new  = np.zeros(n_samples, dtype = node_attbs.dtype)
    node_idxs_new   = np.zeros(n_samples, dtype = node_idxs.dtype)
    j = 0
    for i in range(n_nodes):

        # For interior and free-surface nodes, the indexing does not need to be
        # changed.
        node_attbs_new[j]   = node_attbs[i]
        node_idxs_new[j]    = node_idxs[i]
        
        # A vertex attribute of 2 or 5 indicates a fluid-solid boundary node.
        # (2 is first-order, 5 is second-order.)
        if (node_attbs[i] == 2) or (node_attbs[i] == 5):

            j = j + 1

            # Repeat the node index (displacement is specified twice at this
            # node).
            node_idxs_new[j]    = node_idxs[i]
            
            # For the repeated node, set a new attribute to indicate it is on
            # the liquid side of the boundary.
            if node_attbs[i] == 2:

                node_attbs_new[j] = 6

            elif node_attbs[i] == 5:

                node_attbs_new[j] = 7

        j = j + 1
        
    node_idxs   = node_idxs_new
    node_attbs  = node_attbs_new

    return node_idxs, node_attbs

def read_eigenvector(i_mode, path_eigvec_base):
    '''
    Reads a single eigenfunction from a .dat file output by NormalModes.
    
    Input:
    
    See 'Definitions of variables'.

    Output:

    See 'Definitions of variables'.
    '''
    
    # Read an eigenvector (a flattened list of vector displacements).
    path_eigvec = '{:}_{:d}.dat'.format(path_eigvec_base, i_mode)
    eigvec_flat= np.fromfile(path_eigvec, dtype = 'float64')
    
    # Put the eigenvector in the form (n, 3).
    n_eigvec_flat = len(eigvec_flat)
    n_eigvec_flat_mod_3 = (n_eigvec_flat % 3)
    if n_eigvec_flat_mod_3 != 0:

        raise ValueError('Size of flattened eigenvector array is not a multiple of 3.')
    #    
    eigvec     = eigvec_flat.reshape((int(len(eigvec_flat)/3), 3))
  
    return eigvec

def read_mode(dir_NM, i_mode, path_eigvec_base):
    '''
    Read information about one mode.

    Input:

    dir_PM, dir_NM, i_mode
        See 'Definitions of variables'.

    Output:

    freq, nodes, node_idxs, node_attbs, eigvec
        See 'Definitions of variables'.
    '''
    
    # Read the eigenvalue of this mode.
    dir_processed           = os.path.join(dir_NM, 'processed')
    file_eigval_list        = os.path.join(dir_processed, 'eigenvalue_list.txt')
    i_mode_list, freq_list  = read_eigenvalues(file_eigval_list)
    i_mode_list             = np.array(i_mode_list, dtype = np.int)
    freq_list               = np.array(freq_list)
    freq                    = freq_list[np.where(i_mode_list == i_mode)[0][0]]
   
    # Read the eigenvector.
    eigvec = read_eigenvector(i_mode, path_eigvec_base) 

    return freq, eigvec

# Reading NMPostProcess files. ------------------------------------------------
def read_index_lists(dir_NM):
    '''
    Read the index lists file generated by get_indices_of_regions().

    Input:

    dir_NM
        See 'Definitions of variables'.

    Output:

    index_lists
        See 'Definitions of variables'.
    '''

    # Find path to index lists file.
    dir_processed = os.path.join(dir_NM, 'processed')
    path_index_lists = os.path.join(dir_processed, 'index_lists.txt')

    # Read the header.
    with open(path_index_lists, 'r') as in_id:

        header = in_id.readline()

    # Get the index list lengths from the header.
    index_list_lengths = [int(x) for x in header.split()]

    # Read the index lists.
    index_lists_raw = np.loadtxt(path_index_lists, dtype = np.int, skiprows = 1, comments = '#')

    # Separate the index lists.
    index_lists = []
    index_list_length_cumulative = 0
    for index_list_length in index_list_lengths:
        
        i0 = index_list_length_cumulative
        i1 = i0 + index_list_length
        index_lists.append(index_lists_raw[i0 : i1])

        index_list_length_cumulative = index_list_length_cumulative + index_list_length
    
    return index_lists

def read_info_for_projection(dir_PM, dir_NM):
    '''
    Read information about the mesh required for doing projection.

    Input:

    dir_PM, dir_NM
        See 'Definitions of variables'.

    Returns:

    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists
        See 'Definitions of variables'.
    
    '''

    # Read node coordinates.
    dir_processed = os.path.join(dir_NM, 'processed')
    path_nodes = os.path.join(dir_processed, 'nodes.txt')
    nodes = np.loadtxt(path_nodes)

    # Read sample indices and attributes.
    node_idxs, node_attbs = load_sample_indices_and_attribs(dir_NM)

    # Read the discontinuity radius information.
    path_discon_info = os.path.join(dir_PM, 'radii.txt')
    r_discons, state_outer = read_discon_file(path_discon_info)
    n_discons = len(r_discons)

    # Read lists of indices of samples in interior regions and on discontinuities.
    index_lists = read_index_lists(dir_NM) 

    return nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists 

def get_eigvec_path_base(dir_NM):
    '''
    Determine the common root path for all of the NM output files.

    Input:

    dir_NM
        See 'Definitions of variables'.


    Output:

    eigvec_path_base
        See 'Defintions of variables'.
    '''

    # Look for all files in the output directory ending in *.dat.
    regex_eigvec = '*.dat'
    path_regex_eigvec = os.path.join(dir_NM, regex_eigvec)
    eigvec_path_list = glob(path_regex_eigvec)
    #
    for eigvec_path in eigvec_path_list:

        # Remove .dat suffix.
        eigvec_path = eigvec_path[:-4]

        # Check this is a mode file (ends in an integer).
        eigvec_path_split = eigvec_path.split('_')
        try:

            i_mode = int(eigvec_path_split[-1])
            eigvec_path_base = '_'.join(eigvec_path_split[:-1])

            # Return the first matching pattern.
            return eigvec_path_base

        except ValueError:

            pass

    raise ValueError('No files of correct file name format found in directory {:}'.format(dir_NM))

# Generic functions. ----------------------------------------------------------
def xyz_to_rlonlat(x, y, z):
    '''
    Converts from Cartesian coordinates to radius, longitude and latitude.
    https://mathworld.wolfram.com/SphericalCoordinates.html

    Input:

    x, y, z
        The Cartesian coordinates.

    Returns:

    r   Radial coordinate.
    lon Longitude (radians between -pi and pi).
    lat Latitude (radians between -pi/2 and pi/2).
    '''

    r       = np.sqrt(x**2.0 + y**2.0 + z**2.0)
    theta   = np.arccos(z/r)
    lat     = (np.pi/2.0) - theta
    lon     = np.arctan2(y, x)

    return r, lon, lat

def rlonlat_to_xyz(r, lon, lat):
    '''
    Converts from radius, longitude and latitude to Cartesian coordinates.
    https://mathworld.wolfram.com/SphericalCoordinates.html

    Input:

    r   Radial coordinate.
    lon Longitude (radians).
    lat Latitude (radians).

    Returns:

    x, y, z
        The Cartesian coordinates.
    '''

    # Theta: Angle downward from z axis.
    theta = (np.pi/2.0) - lat
        
    x = r*np.sin(theta)*np.cos(lon)
    y = r*np.sin(theta)*np.sin(lon)
    z = r*np.cos(theta)
    
    return x, y, z

# Common tools for NMPostProcess. --------------------------------------------
def get_discon_info(r_discons, state_outer):
    '''
    Constructs useful arrays based on discontinuity information.

    Input:

    r_discons, r_surface
        See 'Definitions of variables'.

    Returns:
    
    r_discon_midpoints, state_list, n_interior_discons
        See 'Definitions of variables'.
    '''
    
    r_surface = r_discons[0]
    r_interior_discons = r_discons[1:]

    # Count the number of shells (for example, Earth has three shells: solid inner core, fluid outer core, and solid mantle).
    n_interior_discons = len(r_interior_discons)
    
    # Make a list of the mid-points between discontinuities.
    if n_interior_discons > 1:
        
        r_discon_midpoints = 0.5*(r_interior_discons[:-1] + r_interior_discons[1:])

        # Add end points for bracketing.
        r_discon_midpoints = np.concatenate([[r_surface], r_discon_midpoints, [0.0]])

    else:

        r_discon_midpoints = None

    # Create a list of the state of each shell (for example, Earth's is ['solid', 'liquid', 'solid'].
    if state_outer == 'solid':

        i_offset = 0

    elif state_outer == 'liquid':

        i_offset = 1

    else:

        raise ValueError('state_outer: {:}'.format(state_outer))
    
    state_list = []
    n_shells = n_interior_discons + 1
    for i in range(n_shells):

        if ((i + i_offset) % 2 == 0):

            state_list.append('solid')

        else:

            state_list.append('liquid')

    return r_discon_midpoints, state_list, n_interior_discons

def find_r_max(nodes, node_idxs, eigvec, index_lists, r_min = None):
    '''
    For a specified displacement field, find the radius at which the maximum displacement occurs.

    Input

    nodes, node_idxs, eigvec, index_lists 
        See 'Definitions of variables'.
    r_min   A minimum radius. Points inside this radius will be ignored. If 'default', the minimum radius will be 10% of the outer radius.

    Output

    r_max, i_region_max
        See 'Definitions of variables.'
    S_max
        The maximum absolute value of displacement.
    '''

    # If a minimum radius is specified, discard points inside this radius.
    if r_min is not None:

        # Find indices of allowed samples, and set other samples to 0.
        r_samples = np.linalg.norm(nodes[node_idxs], axis = 1)
        r_condition = (r_samples < r_min)
        j_ignore = np.where(r_condition)[0]
        eigvec[j_ignore, :] = 0.0
        
    # Calculate amplitude of eigenfunction at each sample. 
    S = np.linalg.norm(eigvec, axis = 1)

    # Find index of sample with greatest amplitude.
    j       = np.argmax(S)
    S_max   = S[j]
    i       = node_idxs[j]
    node_i  = nodes[i, :]
    r_max     = np.linalg.norm(node_i)
    
    # Find which region the maximum-amplitude sample belongs to.
    found = False
    for i_region, index_list in enumerate(index_lists):

        if j in index_list:
            
            found = True
            i_region_max = i_region
            break

    return r_max, i_region_max, S_max

def interpolate_eigvec_onto_sphere(path_interpolator_fmt, r_q, i_region_q, nodes, node_idxs, eigvec, index_lists, n_lat_grid):
    '''
    Interpolates the 3D displacement field onto a regular grid on a sphere with a specified radius.  

    Input:

    dir_processed, r_q, i_region_q, nodes, node_idxs, eigvec, eigvec, index_lists, n_lat_grid
        See 'Definitions of variables.'
    Note: If i_region_q specifies a discontinuity (case 1), then r_q is ignored.

    Output:

    lon_grid, lat_grid, eigvec_grid
        See 'Definitions of variables.'
    '''

    # Check if the interpolator has already been created.
    if path_interpolator_fmt is not None:

         path_interpolator = path_interpolator_fmt.format(i_region_q)

    else:

        path_interpolator = None

    # Make lists of the regions which are discontinuities and which are interiors.
    n_regions = len(index_lists)
    n_shells = (n_regions + 1)//3
    #
    #i_region_interior = [3*i + 1 for i in range(n_shells)]
    i_region_discon = []
    for i in range(n_shells):

        i_region_discon.append(3*i - 1)
        i_region_discon.append(3*i)

    i_region_discon = i_region_discon[1:]

    # Case 1: The query point is within one of the discontinuities.
    if i_region_q in i_region_discon:

        # Find the points from the given discontinuity.
        j = index_lists[i_region_q]
        eigvec = eigvec[j, :]
        nodes = nodes[node_idxs[j], :]

        # Get the longitude and latitude of the nodes.
        r_nodes, lon_nodes, lat_nodes = xyz_to_rlonlat(*nodes.T) 

        # Use the ssrfpy angle convention (longitude between 0 and 2*pi).
        lon_nodes[lon_nodes < 0.0] = lon_nodes[lon_nodes < 0.0] + 2.0*np.pi

        # Prepare ssrfpy input parameters.
        n_lon_grid      = (2*n_lat_grid) - 1
        ssrfpy_kwargs   = { 'n'             :   n_lat_grid - 1,
                            'method'        :   'linear',
                            'degrees'       :   False,
                            'use_legendre'  :   False}

        # Interpolate onto a regular grid using ssrfpy.
        # Each component is interpolated separately.
        lon_grid, lat_grid, eigvec_x_grid = ssrfpy.interpolate_regular_grid(lon_nodes, lat_nodes, eigvec[:, 0], **ssrfpy_kwargs)
        _, _, eigvec_y_grid = ssrfpy.interpolate_regular_grid(lon_nodes, lat_nodes, eigvec[:, 1], **ssrfpy_kwargs)
        _, _, eigvec_z_grid = ssrfpy.interpolate_regular_grid(lon_nodes, lat_nodes, eigvec[:, 2], **ssrfpy_kwargs)
           
        # Remove extra row added by ssrfpy.
        lon_grid        = lon_grid[:, :-1]
        lat_grid        = lat_grid[:, :-1]
        eigvec_x_grid   = eigvec_x_grid[:, :-1]
        eigvec_y_grid   = eigvec_y_grid[:, :-1] 
        eigvec_z_grid   = eigvec_z_grid[:, :-1]

        # Recombine output into a single array.
        eigvec_grid = np.array([eigvec_x_grid, eigvec_y_grid, eigvec_z_grid])
        eigvec_grid = np.moveaxis(eigvec_grid, 0, -1)

    # Case 2: The query point is within the interior of one of the shells.
    else:

        # If no interpolator file is specified, or the interpolator file is specified but doesn't exist, we calculate a new interpolant.
        # Note: Short-circuiting of 'or' conditional avoids os.path.exists(None) which would raise an error.
        if (path_interpolator is None) or not (os.path.exists(path_interpolator)):
        
            # Extract the nodes from the interior region and its surrounding discontinuities.
            # The inner region only has one bounding discontinuity.
            if i_region_q == (n_regions - 1):
                
                i_region_list = [i_region_q - 1, i_region_q]

            # Other regions have two bounding discontinuities.
            else:

                i_region_list = [i_region_q - 1, i_region_q, i_region_q + 1]
            #
            j = np.concatenate([index_lists[i] for i in i_region_list])
            eigvec = eigvec[j, :]
            nodes = nodes[node_idxs[j], :]


            
            # Create a linear interpolation function.
            interpolator = LinearNDInterpolator(nodes, eigvec)

            if path_interpolator is not None:

                print('Saving linear interpolation file {:}'.format(path_interpolator))
                with open(path_interpolator, 'wb') as interpolator_file_obj:

                    pickle.dump(interpolator, interpolator_file_obj)

        # If a linear interpolant file already exists, it is loaded to save computation time.
        else:

            print('Linear interpolation file {:} already exists, loading...'.format(path_interpolator))
            with open(path_interpolator, 'rb') as interpolator_file_obj:
                
                interpolator = pickle.load(interpolator_file_obj)
            
        # Build a regular grid in longitude and latitude.
        # For consistency with Case 1, we use the grid from ssrfpy.interpolate_regular_grid().
        n_lon_grid = 2*n_lat_grid - 1
        lon_span = np.linspace(0.0, 2.0*np.pi, n_lon_grid, endpoint = True)[:-1]
        lat_span = np.linspace(-np.pi/2.0, np.pi/2.0, n_lat_grid, endpoint=True)
        #
        lon_grid, lat_grid = np.meshgrid(lon_span, lat_span)

        # Find the Cartesian coordinates of the lon/lat grid.
        x_grid, y_grid, z_grid = rlonlat_to_xyz(r_q, lon_grid, lat_grid)
           
        # Find the eigenfunction at the grid points using interpolation.
        eigvec_grid = interpolator((x_grid, y_grid, z_grid))

    return lon_grid, lat_grid, eigvec_grid

# Tools for projecting into vector spherical harmonics. -----------------------
def unit_vectors_at_points(lon, lat):
    '''
    Calculates unit coordinate vectors at specified coordinates.

    Input

    [n]     Number of query points
    lon     (n) Longitude of query points.
    lat     (n) Latitude of query points.

    Output

    r_hat   (n, 3) Outward radial unit vector at each of the query points.
    e_hat   (n, 3) Eastward unit vector at each of the query points.
    n_hat   (n, 3) Northward unit vector at each of the query points.
    '''

    # Find shape of output arrays.
    assert lon.shape == lat.shape
    grid_shape = lon.shape
    vector_shape = (*grid_shape, 3)

    # Calculate unit radial vectors.
    r_hat = np.zeros(vector_shape)
    r_hat[..., 0] = np.cos(lon)*np.cos(lat)
    r_hat[..., 1] = np.sin(lon)*np.cos(lat)
    r_hat[..., 2] = np.sin(lat)
    
    # Calculate unit vectors in the eastward direction.
    e_hat       = np.zeros(vector_shape)
    e_hat[..., 0] = -np.sin(lon)
    e_hat[..., 1] =  np.cos(lon)
    
    # Calculate vectors in the northward direction.
    n_hat       = np.zeros(vector_shape)
    n_hat[..., 0] = -np.cos(lon)*np.sin(lat)
    n_hat[..., 1] = -np.sin(lon)*np.sin(lat)
    n_hat[..., 2] =  np.cos(lat)
    
    return r_hat, e_hat, n_hat

def project_along_unit_vectors(s, r_hat, e_hat, n_hat):
    '''
    Find the radial, eastward and northward components of a vector field by taking the dot product of each vector sample with the radial, eastward and northward unit vectors at the sample location.

    Input

    [n]     The number of nodes.
    s       (n, 3) The vector at each node.
    r_hat   (n, 3) The outward radial unit vector at each node.
    e_hat   (n, 3) The eastward unit vector at each node.
    n_hat   (n, 3) The northward unit vector at each node.

    Output

    s_r, s_e, s_n
        (n) The radial, east and north componets of the vector field at each sample point.
    '''

    # Calculate the dot product at each sample point.
    s_r = np.sum(s*r_hat, axis = -1)
    s_e = np.sum(s*e_hat, axis = -1)
    s_n = np.sum(s*n_hat, axis = -1)
        
    return s_r, s_e, s_n

def transform_to_spherical_harmonics(s_r_grid, s_n_grid, s_e_grid, n_lat_grid, n_lon_grid, l_max):
    '''
    Transforms a vector field into vector spherical harmonics.

    Input:

    s_r_grid, s_n_grid, s_e_grid, n_lat_grid, n_lon_grid, l_max
        See 'Definitions of variables'.

    Output:

    Ulm, Vlm, Wlm, l_list, m_list, sh_calculator
        See 'Definitions of variables'.
    '''

    # Use SHTns to calculate the vector spherical harmonics.
    #
    # Create an instance of the spherical harmonic transform object and set the grid.
    m_max = l_max
    #sh_calculator   = shtns.sht(l_max, m_max, norm = shtns.sht_orthonormal)
    sh_calculator   = shtns.sht(l_max, m_max)
    grid_type       =       shtns.sht_reg_fast          \
                        |   shtns.SHT_SOUTH_POLE_FIRST  \
                        |   shtns.SHT_PHI_CONTIGUOUS
    sh_calculator.set_grid(n_lat_grid, n_lon_grid, flags = grid_type)
    #
    # Transform the spatial vector components (radial, theta and phi) into vector spherical harmonics.
    #
    # Initialise the output arrays which will contain the coefficients.
    Ulm = sh_calculator.spec_array()
    Vlm = sh_calculator.spec_array()
    Wlm = sh_calculator.spec_array()
    #
    # Calculate the coefficients.
    sh_calculator.spat_to_SHqst(
                np.ascontiguousarray(s_r_grid),
                np.ascontiguousarray(-1.0*s_n_grid),
                np.ascontiguousarray(s_e_grid),
                Ulm, Vlm, Wlm)
    
    # Retrieve the l- and m-values (angular order and degree) corresponding to each coefficient.
    l_list = sh_calculator.l
    m_list = sh_calculator.m

    # Note: No longer return sh_calculator due to shtns initialisation bug.
    #return Ulm, Vlm, Wlm, l_list, m_list, sh_calculator
    return Ulm, Vlm, Wlm, l_list, m_list

def project_from_spherical_harmonics(sh_calculator, Ulm, Vlm, Wlm):
    '''
    Calculates the radial, consoidal and toroidal components of a vector field from the vector spherical harmonic coefficients. 

    Input:

    sh_calculator, Ulm, Vlm, Wlm
        See 'Definitions of variables'.

    Output

    Ur, Ve, Vn, We, Wn
        See 'Definitions of variables'.
    '''

    # Do the inverse spherical harmonic transform (i.e. synthesis) of the radial, consoidal and toroidal coefficients separately to get the spatial representation of these parts of the field.
    # Note that zero_spec is used to set the other two components to zero in the calculation, and unwanted output components are sent to zero_spat.
    zero_spec   = sh_calculator.spec_array()
    zero_spat   = sh_calculator.spat_array()
     
    # Get radial part of field.
    Pr          = sh_calculator.spat_array()
    sh_calculator.SHqst_to_spat(
                Ulm, zero_spec, zero_spec,
                Pr, zero_spat, zero_spat)
                
    # Get consoidal part of field.
    Vn = sh_calculator.spat_array()
    Ve = sh_calculator.spat_array()
    sh_calculator.SHqst_to_spat(
                zero_spec, Vlm, zero_spec,
                zero_spat, Vn, Ve)
    # Convert from theta component to north component.
    Vn = Vn*-1.0
    ## Calculate the magnitude of the consoidal field.
    #B   = np.sqrt(Ve**2.0 + Vn**2.0) 
    
    # Get toroidal part of field.
    Wn = sh_calculator.spat_array()
    We = sh_calculator.spat_array()
    sh_calculator.SHqst_to_spat(
                zero_spec, zero_spec, Wlm,
                zero_spat, Wn, We)
    # Convert from theta component to north component.
    Wn = Wn*-1.0
    ## Calculate the magnitude of the toroidal field.
    #C   = np.sqrt(We**2.0 + Wn**2.0)
    
    return Pr, Ve, Vn, We, Wn

# Vector-spherical-harmonic projection at one radius ('quick mode'). ----------
def pre_projection(dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode):
    '''
    Load mode information, discard second-order nodes, find maximum displacement and normalise eigenvector.
    '''

    # Note: Must be an even number.
    n_lat_grid = 6*l_max

    # Define directories.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read the information about the mode.
    freq, eigvec = read_mode(dir_NM, i_mode, eigvec_path_base)

    # Discard information about second-order nodes.
    i_allowed   = np.where((node_attbs == 0) | (node_attbs == 1) | (node_attbs == 2) | (node_attbs == 6))[0]
    node_idxs   = node_idxs[i_allowed]
    node_attbs  = node_attbs[i_allowed]
    eigvec      = eigvec[i_allowed, :]
    index_lists = [np.intersect1d(x, i_allowed) for x in index_lists]

    # Find the radial coordinate where the largest displacement occurs.
    r_max, i_region_max, eigvec_max = find_r_max(nodes, node_idxs, eigvec, index_lists, r_min = 0.1*r_discons[0])

    # Normalise the eigenvector, for better numerical behavior.
    eigvec = eigvec/eigvec_max

    return n_lat_grid, dir_processed, freq, node_idxs, node_attbs, eigvec, index_lists, r_max, i_region_max, eigvec_max

def process_one_depth(path_interpolant_fmt, r_sample, i_region_sample, nodes, node_idxs, eigvec, index_lists, n_lat_grid, l_max):
    '''
    Interpolate, calculate unit vectors, project along unit vectors, and transform from vector components to vector spherical harmonics.
    '''

    # At this radial coordinate, interpolate the displacement field onto the sphere.
    #interpolator_path_fmt = os.path.join(dir_processed, 'interpolator_{:>05d}_{:}.pkl'.format(i_mode, '{:>03d}'))
    lon_grid, lat_grid, eigvec_grid = interpolate_eigvec_onto_sphere(path_interpolant_fmt, r_sample, i_region_sample, nodes, node_idxs, eigvec, index_lists, n_lat_grid)
    n_lon_grid = lon_grid.shape[1]

    # At the grid points, calculate unit vectors in the radial, east and north directions (in terms of the Cartesian basis).
    r_hat_grid, e_hat_grid, n_hat_grid = unit_vectors_at_points(lon_grid, lat_grid)

    # Project the vector field into the radial, east and north directions.
    eigvec_r_grid, eigvec_e_grid, eigvec_n_grid = project_along_unit_vectors(eigvec_grid, r_hat_grid, e_hat_grid, n_hat_grid)

    # Transform vector spatial components to vector spherical harmonics.
    # Note: No longer return sh_calculator due to shtns initialisation bug.
    #Ulm, Vlm, Wlm, l_list, m_list, sh_calculator = \
    Ulm, Vlm, Wlm, l_list, m_list = \
        transform_to_spherical_harmonics(
            eigvec_r_grid, eigvec_n_grid, eigvec_e_grid, n_lat_grid, n_lon_grid, l_max)

    return Ulm, Vlm, Wlm

def save_spectral(dir_processed, i_mode, coeffs, header_info):

    # Determine whether the output is 'quick' or 'full'.
    n_radii = coeffs.shape[0]
    if n_radii == 1:

        option = 'quick'

    else:

        option = 'full'

    # Save spectral output.
    dir_spectral = os.path.join(dir_processed, 'spectral')
    file_out_spectral = '{:}_spectral_{:>05d}.npy'.format(option, i_mode)
    path_out_spectral = os.path.join(dir_spectral, file_out_spectral)
    print('Saving spectral data to {:}'.format(path_out_spectral))
    np.save(path_out_spectral, coeffs)

    # Save spectral header information.
    header_spectral = np.array([header_info['eigvec_max'],
                                header_info['r_max'],
                                header_info['i_region_max'],
                                *header_info['r_sample'],
                                *header_info['i_sample']])
    file_out_spectral_header = '{:}_spectral_header_{:>05d}.npy'.format(option, i_mode)
    path_out_spectral_header = os.path.join(dir_spectral, file_out_spectral_header)
    print('Saving spectral data header to {:}'.format(path_out_spectral_header))
    np.save(path_out_spectral_header, header_spectral)

    return

def vsh_projection_quick(dir_PM, dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode, save_spatial = False):
    '''
    Calculate vector-spherical-harmonic coefficients of displacement field at the radius of maximum displacement.

    Input:

    dir_PM, dir_NM, l_max, eigvec_path_base, nodes_node_idxs, node_attbs, index_lists, r_discons, i_mode, save_spatial
        See 'Definitions of variables'.

    Output:

    None (results are saved to file)
    '''

    # Load mode information, discard second-order nodes, find maximum displacement and normalise eigenvector.
    n_lat_grid, dir_processed, freq, node_idxs, node_attbs, eigvec, \
    index_lists, r_max, i_region_max, eigvec_max = pre_projection(
            dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode)

    # Interpolate, calculate unit vectors, project along unit vectors, and transform from vector components to vector spherical harmonics.
    Ulm, Vlm, Wlm = process_one_depth(None, r_max, i_region_max, nodes, node_idxs, eigvec, index_lists, n_lat_grid, l_max)

    if save_spatial:

        raise NotImplementedError

        ## Calculate the spatial representation of the radial, consoidal and toroidal components.
        #Ur_grid, Ve_grid, Vn_grid, We_grid, Wn_grid = \
        #    project_from_spherical_harmonics(sh_calculator, Ulm, Vlm, Wlm)

        ## Save spatial output.
        #array_out_spatial = np.array([eigvec_grid[..., 0], eigvec_grid[..., 1], eigvec_grid[..., 2], eigvec_r_grid, eigvec_e_grid, eigvec_n_grid, Ur_grid, Ve_grid, Vn_grid, We_grid, Wn_grid])
        #dir_spatial = os.path.join(dir_processed, 'spatial')
        #mkdir_if_not_exist(dir_spatial)
        #file_out_spatial = 'quick_spatial_{:>05d}.npy'.format(i_mode)
        #path_out_spatial = os.path.join(dir_spatial, file_out_spatial)
        #print('Saving spatial data to {:}'.format(path_out_spatial))
        #np.save(path_out_spatial, array_out_spatial)

    # Save spectral output including header.
    # Note: Insert singleton dimension for consistency with 'full' mode.
    coeffs = np.array([Ulm, Vlm, Wlm])
    coeffs = np.expand_dims(coeffs, 0)
    header_info = { 'eigvec_max'    : eigvec_max,
                    'r_max'         : r_max,
                    'i_region_max'  : i_region_max,
                    'r_sample'      : [r_max],
                    'i_sample'      : [i_region_max]}
    save_spectral(dir_processed, i_mode, coeffs, header_info)

    ## Save spectral output.
    #array_out_spectral = np.array([Ulm, Vlm, Wlm])
    ##
    ## Add a header line with the scale information.
    #array_out_spectral = np.insert(array_out_spectral, 0, [eigvec_max, 0.0, 0.0], axis = 1)
    ##
    ## Add header with maximum radius information.
    #array_out_spectral = np.insert(array_out_spectral, 0, [r_max, i_region_max, 0.0], axis = 1)
    ##
    #dir_spectral = os.path.join(dir_processed, 'spectral')
    #file_out_spectral = 'quick_spectral_{:>05d}.npy'.format(i_mode)
    #path_out_spectral = os.path.join(dir_spectral, file_out_spectral)
    #print('Saving spectral data to {:}'.format(path_out_spectral))
    #np.save(path_out_spectral, array_out_spectral)

    return

def vsh_projection_quick_wrapper(dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, save_spatial = False):
    '''
    A wrapper for vsh_projection_quick(), which assembles the relevant information.

    Input:

    dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, save_spatial
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''
    
    #i_mode = np.random.randint(low = 1, high = 83) 

    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Do the projection. 
    vsh_projection_quick(dir_PM, dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode, save_spatial = save_spatial)

    return

def vsh_projection_quick_all_modes(dir_PM, dir_NM, l_max, eigvec_path_base, save_spatial = False):
    '''
    A wrapper for vsh_projection_quick(), which assembles the relevant information and loops over all of the modes.

    Input:

    dir_PM, dir_NM, l_max, eigvec_path_base, save_spatial
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''

    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Get a list of modes.
    i_mode_list = get_list_of_modes_from_output_files(dir_NM)

    # Loop over the mode list.
    for i_mode in i_mode_list:
        
        print('\nProcessing mode: {:>5d}'.format(i_mode))

        # Do the projection. 
        vsh_projection_quick(dir_PM, dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode, save_spatial = save_spatial)

    return

def vsh_projection_quick_parallel(dir_PM, dir_NM, l_max, eigvec_path_base, save_spatial = False):
    '''
    A wrapper for vsh_projection_quick(), which assembles the relevant information and loops over all of the modes using all available processors.

    Input:

    dir_PM, dir_NM, l_max, eigvec_path_base, save_spatial
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''

    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Get a list of modes.
    i_mode_list = get_list_of_modes_from_output_files(dir_NM)

    # Open a parallel pool.
    n_processes = multiprocessing.cpu_count()  
    print('Creating pool with {:d} processes.'.format(n_processes))
    with multiprocessing.Pool(processes = n_processes) as pool:
        
        # Use the pool to analyse the modes specified by num_span.
        # Note that the partial() function is used to meet the requirement of pool.map() of a pickleable function with a single input.
        pool.map(partial(vsh_projection_quick, dir_PM, dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, save_spatial = False), i_mode_list)

    return

# Vector-spherical-harmonic projection at multiple radii ('full mode'). -------
def get_sampling_radii(r_discons, n_radii):
    '''
    Finds radii which are approximately evenly-spaced, including points on the
    inner and outer surface of each discontinuity and at least one point within
    the interior of each shell.

    Input:

    r_discons, n_radii
        See 'Definitions of variables'.

    Output:

    r_sample, i_sample
    '''
    
    n_discons = len(r_discons)
    n_shell = n_discons
    r_srf = r_discons[0]
    r_inner = 0.1*r_srf

    if n_discons == 1:

        r_sample = np.linspace(r_srf, r_inner, num = n_radii)
        i_sample = np.zeros(n_radii, dtype = np.int) + 1
        i_sample[0] = 0

    else:

        if (r_inner > r_discons[-1]):

            print('\nNotImplementedError:')
            print('Radial sampling is chosen to begin at 10% of the outer radius, in this case: {:.1f} km.'.format(r_inner))
            print('However the innermost discontinuity has a smaller radius of {:.1f} km.'.format(r_discons[-1]))
            print('This situation has not yet been implemented in process.get_sampling_radii().')
            raise NotImplementedError('See error message before traceback.')

        assert (n_radii >= 3*n_shell), 'n_radii = {:d} is too small. Require at least {:d} (3 per shell with {:d} shells)'.format(n_radii, 3*n_shell, n_shell)

        # Form arrays of cell radii and thickness.
        # r_shell: The inner and outer radii of each shell.
        # delta_shell: The thickness of each shell.
        r_shell = np.array([*r_discons, r_inner])
        delta_shell = -1.0*np.diff(r_shell)

        # Start with three points per shell.
        n_points_per_shell = np.zeros(n_shell, dtype = np.int) + 3
        n_points = np.sum(n_points_per_shell)

        # Assign points to shells one by one.
        # The aim is to have the most even spacing possible.
        # This is quantified in terms of the variance of the spacing.
        # variance: For a given iteration, the variance of the new spacing
        # formed by adding a point to each shell.
        for _ in range(n_radii - n_points):

            variance = np.zeros(n_shell)

            for j in range(n_shell):

                # Try adding a point to the j_th shell.
                n_points_per_shell[j] = n_points_per_shell[j] + 1

                # Calculate the variance when the point is added to the
                # j_th shell.
                n_intervals_per_shell = n_points_per_shell - 1
                spacing = delta_shell/n_intervals_per_shell
                intervals_list = [np.repeat(spacing[i], n_intervals_per_shell[i]) for i in range(n_shell)]
                intervals = np.concatenate(intervals_list)
                variance[j] = np.var(intervals)

                # Remove the point.
                n_points_per_shell[j] = n_points_per_shell[j] - 1

            # Find the shell which reduces the variance the most and
            # permanently add a point to this shell.
            i_best = np.argmin(variance)
            n_points_per_shell[i_best] = n_points_per_shell[i_best] + 1

        # Calculate the sample points.
        r_sample_list = []
        i_sample_list = []
        for i in range(n_shell):
            
            r_shell_inner = r_shell[i + 1]
            r_shell_outer = r_shell[i]

            r_sample_list.append(np.linspace(r_shell_outer, r_shell_inner, num = n_points_per_shell[i]))

            i_sample_outer_i = 3*i
            i_sample_interior_i = 3*i + 1 
            i_sample_inner_i = 3*i + 2

            i_sample_i = np.zeros(n_points_per_shell[i], dtype = np.int) + i_sample_interior_i
            i_sample_i[0] = i_sample_outer_i

            if i < (n_shell - 1):

                i_sample_i[-1] = i_sample_inner_i

            i_sample_list.append(i_sample_i)

        r_sample = np.concatenate(r_sample_list)
        i_sample = np.concatenate(i_sample_list)

    return r_sample, i_sample

def remove_interpolant_files(path_interpolator_fmt, i_sample):

    # Delete the interpolant files.
    print('Removing interpolant files.')
    i_region_unique = list(set(i_sample))
    i_interior_region = [i for i in i_region_unique if ((i % 3) == 1)]
    for i in i_interior_region: 

         path_interpolator = path_interpolator_fmt.format(i)
         os.remove(path_interpolator)

    return

def vsh_projection_full(dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, r_sample, i_sample, i_mode):
    '''
    Perform VSH projection at specified radial coordinates.
    '''

    # Define directories.
    dir_processed = os.path.join(dir_NM, 'processed')
    path_interpolator_fmt = os.path.join(dir_processed, 'interpolator_{:>05d}_{:}.pkl'.format(i_mode, '{:>03d}'))

    # Load mode information, discard second-order nodes, find maximum displacement and normalise eigenvector.
    n_lat_grid, dir_processed, freq, node_idxs, node_attbs, eigvec, \
    index_lists, r_max, i_region_max, eigvec_max = pre_projection(
            dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, i_mode)

    # Loop over the different sampling radii.
    n_coeffs = (l_max + 1)*(l_max + 2)//2
    n_radii = len(r_sample)
    coeffs = np.zeros((n_radii, 3, n_coeffs), dtype = np.complex)
    #
    for i in range(n_radii):

        print('Processing at radius sample {:>4d} of {:>4d}, radius {:>9.1f} km, region {:>4d}'.format(i + 1, n_radii, r_sample[i], i_sample[i]))

        # Interpolate, calculate unit vectors, project along unit vectors, and transform from vector components to vector spherical harmonics.
        Ulm, Vlm, Wlm = process_one_depth(path_interpolator_fmt, r_sample[i], i_sample[i], nodes, node_idxs, eigvec, index_lists, n_lat_grid, l_max)

        # Store in the output array.
        coeffs[i, 0, :] = Ulm
        coeffs[i, 1, :] = Vlm
        coeffs[i, 2, :] = Wlm

    # Save the output.
    header_info = { 'eigvec_max'    : eigvec_max,
                    'r_max'         : r_max,
                    'i_region_max'  : i_region_max,
                    'r_sample'      : r_sample,
                    'i_sample'      : i_sample}
    save_spectral(dir_processed, i_mode, coeffs, header_info)
    #save_vsh_full(dir_processed, i_mode, coeffs, eigvec_max, r_max, i_region_max)

    # Remove the interpolant files.
    remove_interpolant_files(path_interpolator_fmt, i_sample)

    return coeffs, eigvec_max, r_max, i_region_max

def vsh_projection_full_wrapper(dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, n_radii):
    '''
    A wrapper for vsh_projection_full(), which assembles the relevant information.

    Input:

    dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, n_radii
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''
    
    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')
    #path_interpolator_fmt = os.path.join(dir_processed, 'interpolator_{:>05d}_{:}.pkl'.format(i_mode, '{:>03d}'))

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Get the sampling radii.
    r_sample, i_sample = get_sampling_radii(r_discons, n_radii)

    # Perform the VSH projection at each radius.
    coeffs, eigvec_max, r_max, i_region_max = \
        vsh_projection_full(dir_NM, l_max, eigvec_path_base, nodes, node_idxs,
            node_attbs, index_lists, r_discons, r_sample, i_sample, i_mode)

    return

def vsh_projection_full_all_modes(dir_PM, dir_NM, l_max, eigvec_path_base, n_radii):
    '''
    A wrapper for vsh_projection_full(), which assembles the relevant information.

    Input:

    dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, n_radii
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''
    
    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Get the sampling radii.
    r_sample, i_sample = get_sampling_radii(r_discons, n_radii)

    # Get a list of modes.
    i_mode_list = get_list_of_modes_from_output_files(dir_NM)

    # Loop over list of modes.
    for i_mode in i_mode_list:

        print('\nFull VSH projection: processing mode: {:>5d}'.format(i_mode))

        # Perform the VSH projection at each radius.
        #path_interpolator_fmt = os.path.join(dir_processed, 'interpolator_{:>05d}_{:}.pkl'.format(i_mode, '{:>03d}'))
        coeffs, eigvec_max, r_max, i_region_max = \
            vsh_projection_full(dir_NM, l_max, eigvec_path_base, nodes, node_idxs,
                node_attbs, index_lists, r_discons, i_mode, r_sample, i_sample)

    return

def vsh_projection_full_parallel(dir_PM, dir_NM, l_max, eigvec_path_base, n_radii):
    '''
    A wrapper for vsh_projection_full(), which assembles the relevant information.

    Input:

    dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, n_radii
        See 'Definitions of variables'.

    Output:

    None (output is saved to file).
    '''
    
    # Define directory names.
    dir_processed = os.path.join(dir_NM, 'processed')

    # Read various information about the mesh.
    nodes, node_idxs, node_attbs, r_discons, state_outer, n_discons, index_lists = \
            read_info_for_projection(dir_PM, dir_NM)

    # Get the sampling radii.
    r_sample, i_sample = get_sampling_radii(r_discons, n_radii)

    # Get a list of modes.
    i_mode_list = get_list_of_modes_from_output_files(dir_NM)

    # Open a parallel pool.
    n_processes = multiprocessing.cpu_count()  
    print('Creating pool with {:d} processes.'.format(n_processes))
    with multiprocessing.Pool(processes = n_processes) as pool:
        
        # Use the pool to analyse the modes specified by num_span.
        # Note that the partial() function is used to meet the requirement of pool.map() of a pickleable function with a single input.
        pool.map(partial(vsh_projection_full, dir_NM, l_max, eigvec_path_base, nodes, node_idxs, node_attbs, index_lists, r_discons, r_sample, i_sample), i_mode_list)

    return

# Main. -----------------------------------------------------------------------
def main():
    
    # Read the input file.
    dir_PM, dir_NM, option, l_max, i_mode_str, n_radii = read_input_NMPostProcess()

    # Do pre-processing steps.
    pre_process(dir_PM, dir_NM)
    eigvec_path_base = get_eigvec_path_base(dir_NM)

    # Quick projection (one radius only).
    if option == 'quick':
        
        # Loop over all modes.
        if i_mode_str == 'all':
            
            vsh_projection_quick_all_modes(dir_PM, dir_NM, l_max, eigvec_path_base)

        # Loop over all modes using all available processors.
        elif i_mode_str == 'parallel':

            vsh_projection_quick_parallel(dir_PM, dir_NM, l_max, eigvec_path_base)
        
        # Calculate a single mode.
        else:

            i_mode = int(i_mode_str)
            vsh_projection_quick_wrapper(dir_PM, dir_NM, l_max, i_mode, eigvec_path_base)

    # Full projection (at a range of radii).
    elif option == 'full':

        # Loop over all modes.
        if i_mode_str == 'all':

            vsh_projection_full_all_modes(dir_PM, dir_NM, l_max, eigvec_path_base, n_radii)

        # Loop over all modes using all available processors.
        elif i_mode_str == 'parallel':

            vsh_projection_full_parallel(dir_PM, dir_NM, l_max, eigvec_path_base, n_radii)

        else:

            i_mode = int(i_mode_str)
            vsh_projection_full_wrapper(dir_PM, dir_NM, l_max, i_mode, eigvec_path_base, n_radii)

    else:

        print('Option {:} in file {:} not recognised.'.format(option, input_file))

    return

if __name__ == '__main__':

    main()
